{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/cyprien/Documents/github/pytorch-forecasting\")\n",
    "sys.path.append('../')\n",
    "\n",
    "import hashlib\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_factory.preprocessing import *\n",
    "from utilities.config import load_config\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logging.basicConfig(level=DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(DEBUG)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config_file = '../config/config.yml'\n",
    "use_previous_files = False\n",
    "export = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = load_config(config_file)\n",
    "\n",
    "model = config['model']\n",
    "model_config = config[model]\n",
    "\n",
    "# Create variables from config\n",
    "#  data loading\n",
    "save_folder = config['data']['save']\n",
    "train_file = config['data']['train_path'] + config['data']['stock_prices']\n",
    "test_file = config['data']['test_path'] + config['data']['stock_prices']\n",
    "#  TimeSeries settings\n",
    "max_prediction_length = model_config['sliding_window']['max_prediction_length']\n",
    "min_prediction_length = model_config['sliding_window']['min_prediction_length']\n",
    "max_encoder_length = model_config['sliding_window']['max_encoder_length']\n",
    "min_encoder_length = model_config['sliding_window']['min_encoder_length']\n",
    "batch_size = model_config['sliding_window']['batch_size']\n",
    "\n",
    "related_stocks = model_config['related_stock']\n",
    "train_val_split = model_config['train_val_split']\n",
    "scale = model_config['manual_scale']\n",
    "\n",
    "# define file name for saving StockPricesLoader with specific config\n",
    "hash_ = hashlib.md5(model_config.__str__().encode('utf-8')).hexdigest()\n",
    "export_file_name = f\"{save_folder}/export_{hash_}.p\"\n",
    "logger.debug(f'Export file {export_file_name}')\n",
    "\n",
    "logger.debug(f'Use config {config}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train_raw = pd.read_csv(train_file, parse_dates=['Date'])\n",
    "logger.info(f'{train_file} loaded. shape {df_train_raw.shape}')\n",
    "\n",
    "df_test_raw = pd.read_csv(test_file, parse_dates=['Date'])\n",
    "logger.info(f'{test_file} loaded. shape {df_test_raw.shape}')\n",
    "\n",
    "for df in [df_test_raw, df_train_raw]:\n",
    "    df['Timestamp'] = date_to_timestamp['1d'](df.Date.values.astype(np.int64)).astype(int)\n",
    "    df.SupervisionFlag = df.SupervisionFlag.astype('category')\n",
    "    df.SecuritiesCode = df.SecuritiesCode.astype(str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocess"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fill na & Sort"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train_raw.sort_values(by=['SecuritiesCode', 'Timestamp'], inplace=True)\n",
    "df_train_raw.reset_index(drop=True, inplace=True)\n",
    "df_test_raw.sort_values(by=['SecuritiesCode', 'Timestamp'], inplace=True)\n",
    "df_test_raw.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fill na\n",
    "\n",
    "# Predict target\n",
    "\n",
    "df_train_raw['predict_target'] = df_train_raw.groupby('SecuritiesCode').Target.shift(2).reset_index(drop=True)\n",
    "df_train_raw.dropna(subset=['Target', 'predict_target'], inplace=True)\n",
    "\n",
    "df_train_raw.ExpectedDividend.fillna(value=0, inplace=True)\n",
    "df_train_raw.loc[:, ['Open', 'High', 'Low', 'Close']] = df_train_raw.loc[:, ['Open', 'High', 'Low', 'Close']].fillna(method='ffill')\n",
    "\n",
    "df_test_raw.ExpectedDividend.fillna(value=0, inplace=True)\n",
    "df_test_raw.loc[:, ['Open', 'High', 'Low', 'Close']] = df_test_raw.loc[:, ['Open', 'High', 'Low', 'Close']].fillna(method='ffill')\n",
    "logger.info(f'ExpectedDividend filled with 0. other values filled with ffill')\n",
    "\n",
    "if df_train_raw.isna().sum(axis=0).any():\n",
    "    logger.warning('na values in train dataset')\n",
    "if df_test_raw.isna().sum(axis=0).any():\n",
    "    logger.warning('na values in test dataset')\n",
    "\n",
    "df_train, df_val = split_train_val_timeseries(df_train_raw, train_val_split=.95)\n",
    "df_test = df_test_raw.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train_ppc, df_val_ppc, df_test_ppc = df_train.copy(), df_val.copy(), df_test.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### FIx adjusted price"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "cols_to_scale = ['Open', 'High', 'Low', 'Close']\n",
    "\n",
    "def fix_adjusted_price(x):\n",
    "    f = x[x.AdjustmentFactor != 1]\n",
    "    for ts, adj_f, in zip(f.Timestamp, f.AdjustmentFactor):\n",
    "        x.loc[(x.Timestamp <= ts), cols_to_scale] = x.loc[(x.Timestamp <= ts), cols_to_scale] * adj_f\n",
    "    return x\n",
    "\n",
    "df_train_ppc = df_train_ppc.groupby('SecuritiesCode').progress_apply(lambda x: fix_adjusted_price(x)).reset_index(drop=True)\n",
    "df_val_ppc = df_val_ppc.groupby('SecuritiesCode').progress_apply(lambda x: fix_adjusted_price(x)).reset_index(drop=True)\n",
    "df_test_ppc = df_test_ppc.groupby('SecuritiesCode').progress_apply(lambda x: fix_adjusted_price(x)).reset_index(drop=True)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = df_train_ppc[df_train_ppc.AdjustmentFactor != 1]\n",
    "\n",
    "for sc in f.SecuritiesCode.unique()[2:4]:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(df_train_raw[df_train_raw.SecuritiesCode == sc].Date, df_train_raw[df_train_raw.SecuritiesCode == sc].Close,\n",
    "             alpha=.5, label='not adjusted')\n",
    "    plt.plot(df_train_ppc[df_train_ppc.SecuritiesCode == sc].Date, df_train_ppc[df_train_ppc.SecuritiesCode == sc].Close,\n",
    "             label='adjusted')\n",
    "    plt.scatter(df_train_ppc[(df_train_ppc.SecuritiesCode == sc) & (df_train_ppc.AdjustmentFactor != 1)].Date,\n",
    "                df_train_ppc[(df_train_ppc.SecuritiesCode == sc) & (df_train_ppc.AdjustmentFactor != 1)].Close, s=30, c='r',\n",
    "               label=\"Adjustement factor != 1\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cols_to_scale = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "scalers = {}\n",
    "\n",
    "def scale_col(col):\n",
    "    scalers[col] = train_scalers_on_timeseries(df_train, col=col)\n",
    "    scale_timeseries(df_train_ppc, scalers=scalers[col], col=col)\n",
    "    scale_timeseries(df_val_ppc, scalers=scalers[col], col=col)\n",
    "    scale_timeseries(df_test_ppc, scalers=scalers[col], col=col)\n",
    "\n",
    "for col in cols_to_scale:\n",
    "    scale_col(col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Fill missing dates\n",
    "Disabled since missing dates are not really missing. It most likely the stock market being closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# FIll all dates\n",
    "\n",
    "# df_train_ppc = fill_missing_dates(\n",
    "#     df_train_ppc, date_col='Date', timestamp_col='Timestamp', grp_col='SecuritiesCode', freq='1d',\n",
    "#     fill_with_value={'ExpectedDividend': 0}\n",
    "# )\n",
    "#\n",
    "# df_val_ppc = fill_missing_dates(\n",
    "#     df_val_ppc, date_col='Date', timestamp_col='Timestamp', grp_col='SecuritiesCode', freq='1d',\n",
    "#     fill_with_value={'ExpectedDividend': 0}\n",
    "# )\n",
    "#\n",
    "# df_test_ppc = fill_missing_dates(\n",
    "#     df_test_ppc, date_col='Date', timestamp_col='Timestamp', grp_col='SecuritiesCode', freq='1d',\n",
    "#     fill_with_value={'ExpectedDividend': 0}\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Add previous timestamps to test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Add history to val and test dataset so that they have material to work with when predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_test_ppc['is_testing'] = True\n",
    "df_train_ppc['is_testing'] = False\n",
    "df_val_ppc['is_testing'] = False\n",
    "\n",
    "df_test_ppc['is_val'] = False\n",
    "df_train_ppc['is_val'] = False\n",
    "df_val_ppc['is_val'] = True\n",
    "\n",
    "\n",
    "#  Add previous dates to make use of them in the prediction\n",
    "df_val_ppc_ext = pd.concat([\n",
    "    df_train_ppc.groupby('SecuritiesCode').apply(lambda x: x.iloc[-max_encoder_length:]).reset_index(drop=True),\n",
    "    df_val_ppc\n",
    "]).sort_values(by=['SecuritiesCode', 'Timestamp']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "#  Add previous dates to make use of them in the prediction\n",
    "df_test_ppc_ext = pd.concat([\n",
    "    df_val_ppc_ext.groupby('SecuritiesCode').apply(lambda x: x.iloc[-max_encoder_length:]).reset_index(drop=True),\n",
    "    df_test_ppc]\n",
    ").sort_values(by=['SecuritiesCode', 'Timestamp']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# #  Fill missing dates in test dataframe so that the behaviour of TimeSeriesDataSet is always the same.\n",
    "# df_test_ppc_ext = fill_missing_dates(\n",
    "#     df_test_ppc_ext, 'Date', 'Timestamp', 'SecuritiesCode', '1d',\n",
    "#     fill_with_value={'ExpectedDividend': 0, 'is_testing': False}\n",
    "# )\n",
    "#\n",
    "# #  Fill missing dates in val dataframe so that the behaviour of TimeSeriesDataSet is always the same.\n",
    "# df_val_ppc_ext = fill_missing_dates(\n",
    "#     df_val_ppc_ext, 'Date', 'Timestamp', 'SecuritiesCode', '1d',\n",
    "#     fill_with_value={'ExpectedDividend': 0, 'is_val': False}\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Extend days so that TimeSeriesDataSet iterate over the last actual item in test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:data_factory.preprocessing:This function is not ready to be used with something else than test set\n"
     ]
    }
   ],
   "source": [
    "df_test_ppc_ext = add_days(\n",
    "    df_test_ppc_ext,\n",
    "    days=max_prediction_length,\n",
    "    grp_col='SecuritiesCode',\n",
    "    timestamp_col='Timestamp',\n",
    "    date_col='Date'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train_ppc['predict_target'] = df_train_ppc.groupby('SecuritiesCode').Target.shift(2).reset_index(drop=True).fillna(0)\n",
    "df_val_ppc_ext['predict_target'] = df_val_ppc_ext.groupby('SecuritiesCode').Target.shift(2).reset_index(drop=True).fillna(0)\n",
    "df_test_ppc_ext['predict_target'] = df_test_ppc_ext.groupby('SecuritiesCode').Target.shift(2).reset_index(drop=True).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from data_factory.prepared_data import PreparedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = PreparedData(df_train_ppc, df_val_ppc_ext, df_test_ppc_ext, scalers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.export('../data/save/preprocessed_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Some checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_test_ppc_ext.shape[0], df_test_ppc.shape[0] + (2000*max_encoder_length) + (2000*max_prediction_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_val_ppc_ext.shape[0], df_val_ppc.shape[0] + (2000*max_encoder_length)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}