{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.pyplot:Loaded backend module://matplotlib_inline.backend_inline version unknown.\n",
      "DEBUG:matplotlib.pyplot:Loaded backend module://matplotlib_inline.backend_inline version unknown.\n"
     ]
    },
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "951e89f7f2be40b090902de25c21434b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": "42"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/media/cyprien/Data/Documents/Github/pytorch-forecasting\")\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from data_factory.dataLoader import StockPricesLoader\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from tqdm import notebook\n",
    "\n",
    "from utilities import *\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "notebook.tqdm().pandas()\n",
    "\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data_factory.dataLoader:Use init() method to load the data\n",
      "INFO:data_factory.dataLoader:../data/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv loaded. shape (2332531, 12)\n",
      "INFO:data_factory.dataLoader:../data/jpx-tokyo-stock-exchange-prediction/supplemental_files/stock_prices.csv loaded. shape (112000, 12)\n",
      "INFO:data_factory.dataLoader:Missing targets dropped\n",
      "INFO:data_factory.dataLoader:ExpectedDividend filled with 0. other values filled with ffill\n",
      "INFO:data_factory.dataLoader:adjust prices\n",
      " 90%|████████▉ | 1793/2000 [05:32<00:49,  4.17it/s]"
     ]
    }
   ],
   "source": [
    "config = load_config(\"../config/config.yml\")\n",
    "\n",
    "assert config['model'] == 'temporal_fusion_transformer', 'Invalid model in file configuration for this script'\n",
    "\n",
    "dl = StockPricesLoader(use_previous_files=True)\n",
    "if not dl.initialized:\n",
    "    dl.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## TemporalFusionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from pytorch_forecasting.models import TemporalFusionTransformer\n",
    "import logging\n",
    "from logging import WARNING\n",
    "logging.basicConfig(level=WARNING)\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "\n",
    "args = dict(\n",
    "    hidden_size=16, #config['temporal_fusion_transformer']['hidden_size'],\n",
    "    lstm_layers=1, #config['temporal_fusion_transformer']['lstm_layers'],\n",
    "    dropout=config['temporal_fusion_transformer']['dropout'],\n",
    "    attention_head_size=4,#config['temporal_fusion_transformer']['attention_head_size']\n",
    "    # output_size=dl.max_prediction_length,\n",
    "    # max_encoder_length=dl.max_encoder_length\n",
    ")\n",
    "\n",
    "# configure network and trainer\n",
    "trainer = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    gradient_clip_val=0.1,\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergence\n",
    "    # of the gradient for recurrent neural networks\n",
    "    auto_lr_find=True,\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    "    weights_summary=\"top\",\n",
    ")\n",
    "\n",
    "model = TemporalFusionTransformer.from_dataset(\n",
    "    dl.df_train_timeseries,\n",
    "    **args\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Number of parameters in network: {model.size() / 1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## fit network\n",
    "\n",
    "fit = True\n",
    "\n",
    "if fit:\n",
    "    trainer.fit(model, train_dataloaders=dl.train_dl, val_dataloaders=dl.val_dl)\n",
    "else:\n",
    "    model = TemporalFusionTransformer.load_from_checkpoint('././lightning_logs/lightning_logs/version_5/checkpoints/epoch=0-step=49915.ckpt')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "actuals = torch.cat([y for _, (y, _) in tqdm(iter(dl.test_dl))])\n",
    "predictions = trainer.predict(model, (X for X, (y, _) in dl.test_dl))\n",
    "\n",
    "predictions_np = np.array([i.prediction.numpy() for i in predictions]).squeeze(axis=3).reshape(-1, 10)\n",
    "actuals_np = actuals.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "actuals_unscaled = actuals_np.reshape(dl.df_train_ppc.SecuritiesCode.unique().size, -1, 10).copy()\n",
    "predictions_unscaled = predictions_np.reshape(dl.df_train_ppc.SecuritiesCode.unique().size, -1, 10).copy()\n",
    "\n",
    "for i, scaler in enumerate(dl.scalers):\n",
    "    actuals_unscaled[i] = scaler.inverse_transform(actuals_unscaled[i])\n",
    "for i, scaler in enumerate(dl.scalers):\n",
    "    predictions_unscaled[i] = scaler.inverse_transform(predictions_unscaled[i])\n",
    "\n",
    "actuals_unscaled = actuals_unscaled.reshape(-1, 10)\n",
    "predictions_unscaled = predictions_unscaled.reshape(-1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_test_res = dl.df_test_ppc.copy()\n",
    "\n",
    "df_test_res['close_true'] = actuals_np[:, 0].flatten()\n",
    "df_test_res['close_pred'] = predictions_np[:, 0].flatten()\n",
    "\n",
    "df_test_res['close_true_unscaled'] = actuals_unscaled[:, 0].flatten()\n",
    "df_test_res['close_pred_unscaled'] = predictions_unscaled[:, 0].flatten()\n",
    "\n",
    "df_test_res['target_true'] = (actuals_np[:, 1] - actuals_np[:, 0]) / actuals_np[:, 0]\n",
    "df_test_res['target_pred'] = (predictions_np[:, 1] - predictions_np[:, 0]) / predictions_np[:, 0]\n",
    "\n",
    "df_test_res['target_true_unscaled'] = (actuals_unscaled[:, 1] - actuals_unscaled[:, 0]) / actuals_unscaled[:, 0]\n",
    "df_test_res['target_pred_unscaled'] = (predictions_unscaled[:, 1] - predictions_unscaled[:, 0]) / predictions_unscaled[:, 0]\n",
    "\n",
    "df_test_res.loc[:, ['Close', 'close_true_unscaled', 'close_pred_unscaled', 'Target', 'target_true_unscaled', 'target_pred_unscaled']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for sc in dl.df_train_ppc.SecuritiesCode.unique()[:3]:\n",
    "    df = df_test_res[df_test_res.SecuritiesCode == sc]\n",
    "    figure = plt.figure(figsize=(20, 5))\n",
    "    # plt.plot(df.Date, df.Close, label='close true', figure=figure)\n",
    "    plt.plot(df.Date, df.close_true_unscaled, label='close true', figure=figure)\n",
    "    plt.plot(df.Date, df.close_pred_unscaled, label='close pred', figure=figure)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "recreated_target_is_valid = df_test_res.groupby('SecuritiesCode').apply(lambda x: (x.authentic == True).shift(-2).fillna(value=False) & (x.authentic == True).shift(-1).fillna(value=False) & (x.authentic == True)).reset_index(drop=True)\n",
    "evaluated_target = (df_test_res.authentic == True)\n",
    "\n",
    "for sc in df_test_res.SecuritiesCode.unique()[:8]:\n",
    "    df = df_test_res[(df_test_res.SecuritiesCode == sc) & evaluated_target]\n",
    "    figure = plt.figure(figsize=(20, 5))\n",
    "    plt.scatter(df.Date, df.Target, label='true', figure=figure, alpha=.5)\n",
    "    # plt.scatter(df.Date, df.target_true_unscaled, label='true2', figure=figure, alpha=.5)\n",
    "    plt.scatter(df.Date, df.target_pred_unscaled, label='pred', figure=figure, alpha=.5)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from utilities.evaluation import calc_spread_return_sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_test_res['Rank'] = (df_test_res.groupby(\"Date\")[\"target_true_unscaled\"].rank(ascending=False, method=\"first\") - 1).astype(int)\n",
    "calc_spread_return_sharpe(df_test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_test_res['Rank'] = (df_test_res.groupby(\"Date\")[\"target_pred_unscaled\"].rank(ascending=False, method=\"first\") - 1).astype(int)\n",
    "calc_spread_return_sharpe(df_test_res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}