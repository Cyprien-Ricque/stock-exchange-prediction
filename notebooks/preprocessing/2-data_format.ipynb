{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/cyprien/Documents/github/pytorch-forecasting\")\n",
    "sys.path.append('../../')\n",
    "\n",
    "import hashlib\n",
    "\n",
    "from data_factory.preprocessing import *\n",
    "from utilities.config import load_config\n",
    "\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "\n",
    "logging.basicConfig(level=DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config_file = '../../config/config.yml'\n",
    "use_previous_files = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__main__:Export file ../data/save//export_33330b8610da212bf1f1161f2e2ce8c7.p\n",
      "DEBUG:__main__:Use config {'device': 'cpu', 'seed': False, 'model': 'temporal_fusion_transformer', 'data': {'save': '../data/save/', 'suppl': '../data/suppl/', 'train_path': '../data/jpx-tokyo-stock-exchange-prediction/train_files/', 'test_path': '../data/jpx-tokyo-stock-exchange-prediction/supplemental_files/', 'financials': 'financials.csv', 'stock_prices': 'stock_prices.csv', 'options': 'options.csv', 'secondary_stock_price': 'secondary_stock_prices.csv', 'trades': 'trades.csv', 'cosine': 'cosine_df.csv'}, 'rnn': {'sliding_window': {'max_prediction_length': 10, 'min_prediction_length': 10, 'max_encoder_length': 80, 'min_encoder_length': 80, 'batch_size': 64}, 'train_val_split': 1, 'related_stock': 2, 'manual_scale': True, 'hidden_size': 20, 'layers': 3, 'dropout': 0}, 'temporal_fusion_transformer': {'sliding_window': {'max_prediction_length': 5, 'min_prediction_length': 5, 'max_encoder_length': 150, 'min_encoder_length': 150, 'batch_size': 64}, 'train_val_split': 1, 'related_stock': 3, 'manual_scale': True, 'hidden_size': 16, 'lstm_layers': 2, 'dropout': 0.05, 'output_size': 7, 'attention_head_size': 4}, 'gmm': {'path': './cache/', 'n_clusters': 4}, 'optimizer': {'name': 'adam', 'epochs': 10, 'params': {'lr': 0.001, 'regularization': 0.0001}}}\n"
     ]
    }
   ],
   "source": [
    "config = load_config(config_file)\n",
    "\n",
    "model = config['model']\n",
    "model_config = config[model]\n",
    "\n",
    "# Create variables from config\n",
    "#  data loading\n",
    "save_folder = config['data']['save']\n",
    "train_file = config['data']['train_path'] + config['data']['stock_prices']\n",
    "test_file = config['data']['test_path'] + config['data']['stock_prices']\n",
    "#  TimeSeries settings\n",
    "max_prediction_length = model_config['sliding_window']['max_prediction_length']\n",
    "min_prediction_length = model_config['sliding_window']['min_prediction_length']\n",
    "max_encoder_length = model_config['sliding_window']['max_encoder_length']\n",
    "min_encoder_length = model_config['sliding_window']['min_encoder_length']\n",
    "batch_size = model_config['sliding_window']['batch_size']\n",
    "\n",
    "related_stocks = model_config['related_stock']\n",
    "train_val_split = model_config['train_val_split']\n",
    "scale = model_config['manual_scale']\n",
    "\n",
    "# define file name for saving StockPricesLoader with specific config\n",
    "hash_ = hashlib.md5(model_config.__str__().encode('utf-8')).hexdigest()\n",
    "export_file_name = f\"{save_folder}/export_{hash_}.p\"\n",
    "\n",
    "logger.debug(f'Export file {export_file_name}')\n",
    "logger.debug(f'Use config {config}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from data_factory.prepared_data import PreparedData\n",
    "\n",
    "data: PreparedData = PreparedData.from_file(\"../../data/save/augmented_data.pkl\")\n",
    "df_train = data.train\n",
    "df_val = data.val\n",
    "df_test = data.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Create timestamp for TimeSeriesDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['predict_target_topb_1',\n",
       "  'Close_scaled_tops_2',\n",
       "  'Close_scaled_topb_2',\n",
       "  'predict_target_tops_0',\n",
       "  'predict_target',\n",
       "  'High_scaled',\n",
       "  'Close_scaled_topb_1',\n",
       "  'Close_scaled_topf_0',\n",
       "  'predict_target_ewm_10',\n",
       "  'predict_target_ewm_3',\n",
       "  'predict_target_topf_2',\n",
       "  'Close_scaled_topb_0',\n",
       "  'Close_scaled_tops_1',\n",
       "  'predict_target_tops_1',\n",
       "  'Close_scaled_topf_1',\n",
       "  'Close_scaled_ewm_3',\n",
       "  'Open_scaled',\n",
       "  'predict_target_topf_1',\n",
       "  'Low_scaled',\n",
       "  'predict_target_topf_0',\n",
       "  'Close_scaled_ewm_10',\n",
       "  'predict_target_topb_2',\n",
       "  'Close_scaled_tops_0',\n",
       "  'predict_target_tops_2',\n",
       "  'Close_scaled',\n",
       "  'Volume_scaled',\n",
       "  'Close_scaled_topf_2',\n",
       "  'predict_target_topb_0',\n",
       "  'ExpectedDividend',\n",
       "  'AdjustmentFactor'],\n",
       " 30)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'Close_scaled'\n",
    "\n",
    "static_categoricals = ['SecuritiesCode', 'sector_group', 'business_group', 'financial_group']\n",
    "\n",
    "time_varying_known_categoricals = ['dayofweek']\n",
    "time_varying_unknown_categoricals = ['SupervisionFlag']\n",
    "time_idx = 'Timestamp_1'\n",
    "\n",
    "unused = [\n",
    "    'Date', 'RowId', 'Open', 'High', 'Low', 'Close', 'Volume', 'Timestamp', 'Timestamp_1', \n",
    "    'SupervisionFlag', 'Target', 'authentic', 'is_testing', 'is_val'\n",
    "]\n",
    "\n",
    "time_varying_unknown_reals = list(set(df_train.columns) - set(unused) - set(static_categoricals) - \n",
    "                                  set(time_varying_known_categoricals) - set(time_varying_unknown_categoricals)\n",
    "                                 - {time_idx})\n",
    "time_varying_unknown_reals, len(time_varying_unknown_reals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train.loc[:, static_categoricals] = df_train.loc[:, static_categoricals].astype(str)\n",
    "df_val.loc[:, static_categoricals] = df_val.loc[:, static_categoricals].astype(str)\n",
    "df_test.loc[:, static_categoricals] = df_test.loc[:, static_categoricals].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train_timeseries = TimeSeriesDataSet(\n",
    "    df_train,\n",
    "    time_idx=time_idx,\n",
    "    target=target,\n",
    "    group_ids=['SecuritiesCode'],\n",
    "    allow_missing_timesteps=False,\n",
    "\n",
    "    static_categoricals=static_categoricals,\n",
    "\n",
    "    time_varying_unknown_reals=time_varying_unknown_reals,\n",
    "    time_varying_unknown_categoricals=time_varying_unknown_categoricals,\n",
    "    time_varying_known_reals=[],\n",
    "    time_varying_known_categoricals=time_varying_known_categoricals,\n",
    "\n",
    "    min_encoder_length=min_encoder_length,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    min_prediction_length=min_prediction_length,\n",
    "\n",
    "    scalers={col: None for col in list(set(time_varying_unknown_reals) - {target})},\n",
    "    target_normalizer=None,\n",
    "    add_relative_time_idx=model == 'temporal_fusion_transformer',\n",
    "    add_target_scales=False,\n",
    "    add_encoder_length=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_val_timeseries = TimeSeriesDataSet.from_dataset(\n",
    "    df_train_timeseries, df_val,\n",
    "    predict=False,\n",
    "    stop_randomization=True,\n",
    "    min_prediction_length=max_prediction_length,\n",
    "    max_prediction_length=max_prediction_length\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_test_timeseries = TimeSeriesDataSet.from_dataset(\n",
    "    df_train_timeseries, df_test,\n",
    "    allow_missing_timesteps=False,\n",
    "    predict=False,\n",
    "    stop_randomization=True,\n",
    "    min_prediction_idx=df_test[df_test.is_testing == True].Timestamp_1.min() + 1,\n",
    "    min_prediction_length=max_prediction_length,\n",
    "    max_prediction_length=max_prediction_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Batch size of test set to predict one SecuritiesCode at a time.\n",
    "# Created to make debug easier.\n",
    "\n",
    "test_set_size = df_test[df_test.is_testing == True].Timestamp_1.max() - df_test[df_test.is_testing == True].Timestamp_1.min() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### DataLoaders\n",
    "*Just to make sure it works, not exported*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dl = df_train_timeseries.to_dataloader(train=True, batch_size=batch_size, num_workers=12)\n",
    "\n",
    "val_dl = df_val_timeseries.to_dataloader(train=False, batch_size=batch_size, num_workers=12, shuffle=False)\n",
    "\n",
    "test_dl = df_test_timeseries.to_dataloader(\n",
    "    batch_size=test_set_size,\n",
    "    num_workers=12,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from data_factory.prepared_data import TimeSeriesData\n",
    "\n",
    "data_ts = TimeSeriesData(df_train_timeseries, df_val_timeseries, df_test_timeseries, test_set_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_ts.export('../../data/save/timeseries_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "dict_keys(['x_cat', 'x_cont', 'encoder_length', 'decoder_length', 'encoder_target', 'encoder_time_idx_start', 'groups', 'target_scale'])\n",
      "torch.Size([155, 31])\n"
     ]
    }
   ],
   "source": [
    "for X, (y, _) in df_train_timeseries:\n",
    "    print(y.shape)\n",
    "    print(X.keys())\n",
    "\n",
    "    print(X['x_cont'].shape)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}