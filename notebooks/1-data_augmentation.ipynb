{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/cyprien/Documents/github/pytorch-forecasting\")\n",
    "\n",
    "import hashlib\n",
    "\n",
    "from data_factory.preprocessing import *\n",
    "from utilities.config import load_config\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "logging.basicConfig(level=DEBUG)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(DEBUG)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "config_file = '../config/config.yml'\n",
    "use_previous_files = False\n",
    "export = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__main__:Export file ../data/save//export_c812f38e2002410441e38cf0c23469e2.p\n",
      "DEBUG:__main__:Use config {'device': 'cpu', 'seed': False, 'model': 'temporal_fusion_transformer', 'data': {'save': '../data/save/', 'suppl': '../data/suppl/', 'train_path': '../data/jpx-tokyo-stock-exchange-prediction/train_files/', 'test_path': '../data/jpx-tokyo-stock-exchange-prediction/supplemental_files/', 'financials': 'financials.csv', 'stock_prices': 'stock_prices.csv', 'options': 'options.csv', 'secondary_stock_price': 'secondary_stock_price.csv', 'trades': 'trades.csv', 'cosine': 'cosine_df.csv'}, 'rnn': {'sliding_window': {'max_prediction_length': 10, 'min_prediction_length': 10, 'max_encoder_length': 150, 'min_encoder_length': 150, 'batch_size': 64}, 'train_val_split': 1, 'related_stock': 2, 'manual_scale': True, 'hidden_size': 20, 'layers': 3, 'dropout': 0}, 'temporal_fusion_transformer': {'sliding_window': {'max_prediction_length': 10, 'min_prediction_length': 10, 'max_encoder_length': 150, 'min_encoder_length': 150, 'batch_size': 64}, 'train_val_split': 1, 'related_stock': 5, 'manual_scale': True, 'hidden_size': 16, 'lstm_layers': 2, 'dropout': 0.05, 'output_size': 7, 'attention_head_size': 4}, 'gmm': {'path': './cache/', 'n_clusters': 4}, 'optimizer': {'name': 'adam', 'epochs': 10, 'params': {'lr': 0.001, 'regularization': 0.0001}}}\n"
     ]
    }
   ],
   "source": [
    "config = load_config(config_file)\n",
    "\n",
    "model = config['model']\n",
    "model_config = config[model]\n",
    "\n",
    "# Create variables from config\n",
    "#  data loading\n",
    "save_folder = config['data']['save']\n",
    "train_file = config['data']['train_path'] + config['data']['stock_prices']\n",
    "test_file = config['data']['test_path'] + config['data']['stock_prices']\n",
    "#  TimeSeries settings\n",
    "max_prediction_length = model_config['sliding_window']['max_prediction_length']\n",
    "min_prediction_length = model_config['sliding_window']['min_prediction_length']\n",
    "max_encoder_length = model_config['sliding_window']['max_encoder_length']\n",
    "min_encoder_length = model_config['sliding_window']['min_encoder_length']\n",
    "batch_size = model_config['sliding_window']['batch_size']\n",
    "\n",
    "related_stocks = model_config['related_stock']\n",
    "train_val_split = model_config['train_val_split']\n",
    "scale = model_config['manual_scale']\n",
    "\n",
    "# define file name for saving StockPricesLoader with specific config\n",
    "hash_ = hashlib.md5(model_config.__str__().encode('utf-8')).hexdigest()\n",
    "export_file_name = f\"{save_folder}/export_{hash_}.p\"\n",
    "logger.debug(f'Export file {export_file_name}')\n",
    "\n",
    "logger.debug(f'Use config {config}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from data_factory.prepared_data import PreparedData\n",
    "\n",
    "data: PreparedData = PreparedData.from_file(\"../data/save/preprocessed_data.pkl\")\n",
    "df_train = data.train\n",
    "df_val = data.val\n",
    "df_test = data.test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Augmentation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Add related stocks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Len missing Securities Code in cosine_df.csv: 0\n",
      "100%|██████████| 5/5 [01:46<00:00, 21.32s/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.15s/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.09s/it]\n"
     ]
    }
   ],
   "source": [
    "n = related_stocks\n",
    "\n",
    "cosine = pd.read_csv(config['data']['suppl'] + config['data']['cosine'], low_memory=False).rename(columns={'Unnamed: 0': 'ticker'})\n",
    "\n",
    "cosine.set_index('ticker', inplace=True)\n",
    "top = cosine.apply(lambda s: pd.Series(s.nlargest(related_stocks).index)).T.astype(str).rename(columns=str)\n",
    "missing_keys = list(set(df_train.SecuritiesCode.unique()) - set(cosine.columns))\n",
    "logger.info(f\"Len missing Securities Code in {config['data']['cosine']}: {len(missing_keys)}\")\n",
    "\n",
    "top = pd.concat([top, pd.DataFrame({str(i): missing_keys for i in range(n)}, index=missing_keys)])\n",
    "\n",
    "def add_stocks(df: pd.DataFrame):\n",
    "    for t, col in tqdm([(f'top_{i}', str(i)) for i in range(n)]):\n",
    "        df[t] = df.SecuritiesCode.transform(lambda x: top.loc[x, col])\n",
    "\n",
    "        df = df.merge(\n",
    "            df.loc[:, ['SecuritiesCode', 'Timestamp', 'Close', 'Close_scaled']],\n",
    "            how='left', left_on=[t, 'Timestamp'], right_on=['SecuritiesCode', 'Timestamp'],\n",
    "            suffixes=('', f'_{t}')\n",
    "        ).drop(columns=f'SecuritiesCode_{t}')\n",
    "\n",
    "        df[f'Close_scaled_{t}'] = df[f'Close_scaled_{t}']\n",
    "    return df.fillna(value=0)\n",
    "\n",
    "df_train = add_stocks(df_train)\n",
    "df_test = add_stocks(df_test)\n",
    "df_val = add_stocks(df_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Export"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "data = PreparedData(df_train, df_val, df_test, data.scalers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "data.export('../data/save/augmented_data.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}